# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EbMrAL9rXZ39dcXISYaSMh_EJkT_4QMP

# **Membuat Model NLP dengan TensorFlow**

**Nama : Imam Sasongko Jati**

**Kelas :  Belajar Pengembangan Machine Learning**

Menyiapkan dataset Video Game Sales yang telah di unduh dari situs Kaggle [teks link](https://www.kaggle.com/gregorut/videogamesales), serta memilih kolom yang akan digunakan
"""

import pandas as pd
df = pd.read_csv('vgsales.csv')
df = df[['Name','Genre']]

df

"""Melakukan proses One-Hot-Encoding karena label data masih berupa kategorikal dan membuat dataframe baru."""

category = pd.get_dummies(df.Genre)
df_new = pd.concat([df, category], axis=1)
df_new = df_new.drop(columns='Genre')
df_new

"""Merubah nilai-nilai dari dataframe ke dalam bentuk Numpy Array dengan cara menggunakan atribut values agar data dapat diproses oleh model."""

name = df_new['Name'].values
label = df_new[['Action', 'Adventure', 'Fighting', 'Misc', 'Platform','Puzzle','Racing','Role-Playing','Shooter','Simulation','Sports','Strategy']].values

"""Membagi dataset menjadi data validasi 20% dan data training 80% menggunakan fungsi split."""

from sklearn.model_selection import train_test_split
name_train, name_val, label_train, label_val = train_test_split(name, label, test_size=0.2)

"""Mengecek jumlah data yang di split apakah sudah sesuai dengan yang di kehendaki."""

print('Jumlah data train = ',len(name_train) )
print('Jumlah data validasi = ',len(name_val) )
print('Jumlah total data = ',len(name_train)+len(name_val))

"""Mengubah dataset ke bentuk numerik dengan menggunakan fungsi Tokenizer dan selanjutnya mengkonversi setiap sample ke dalama sequence."""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(name_train) 
tokenizer.fit_on_texts(name_val)
 
sekuens_train = tokenizer.texts_to_sequences(name_train)
sekuens_val = tokenizer.texts_to_sequences(name_val)
 
padded_train = pad_sequences(sekuens_train) 
padded_val = pad_sequences(sekuens_val)

"""Membuat model menggunakan layer Embedding dengan dimensi Embedding sebesar 128 serta dimensi input sebesar num_word pada proses tokenizer sebesar 5000, fungsi compile dengan loss function='categorical_crossentropy' dan optimizer = 'adam', serta menambahkan layer LSTM dan mengisi parameter dengan jumlah output 64."""

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=128),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(12, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""Melatih model yang telah dibuat dengan fungsi fit dan jumlah pelatihan/epoch sebanyak 20x."""

history = model.fit(padded_train, label_train, 
                    epochs=20, 
                    validation_data=(padded_val, label_val), verbose=2)

"""Plot loss dan akurasi pada saat training dan validation"""

import matplotlib.pyplot as plt


loss = history.history['loss']
acc = history.history['accuracy']
val_los = history.history['val_loss']
val_acc = history.history['val_accuracy']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Akurasi Pelatihan')
plt.plot(epochs, val_acc, 'b', label='Akurasi Validasi')
plt.title('Akurasi Pelatihan dan Validasi')
plt.xlabel('epoch')
plt.ylabel('Akurasi')
plt.legend(loc=0)
plt.figure()


plt.show()

"""Membuat kelas callback untuk membuat pelatihan berhenti ketika akurasi sebesar 85% telah tercapai"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.85):
      print("\nAkurasi telah mencapai >85%!")
      self.model.stop_training = True
callbacks = myCallback()

"""Melatih model dengan disertai callback agar ketika akurasi 85% tercapai pelatihan model akan berhenti."""

history = model.fit(padded_train, label_train, 
                    epochs=20, 
                    validation_data=(padded_val, label_val), verbose=2, callbacks=[callbacks])